{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FGSM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uiflfa3DbKn"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np "
      ],
      "id": "1uiflfa3DbKn",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-wealth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4f5e35-5fd6-4a2c-dca4-dc44075e8992"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "train_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=True\n",
        ")\n",
        "\n",
        "test_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=False\n",
        ")"
      ],
      "id": "behind-wealth",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 07:30:41--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-10-09 07:30:41--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [       <=>          ]  33.20M  25.7MB/s    in 1.3s    \n",
            "\n",
            "2021-10-09 07:30:42 (25.7 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vertical-venice"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=128, shuffle=False)"
      ],
      "id": "vertical-venice",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJQc2XkDLa04"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 96, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=1, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 10, kernel_size=1), \n",
        "        nn.AvgPool2d(kernel_size=8),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = self.net(x)\n",
        "    return logits.view(-1, 10)"
      ],
      "id": "LJQc2XkDLa04",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRb-0G9590TS",
        "outputId": "42b35c07-78f2-4c0c-bc9c-77c78a463710"
      },
      "source": [
        "# Pretrain classifier\n",
        "classifier = Classifier().cuda()\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "for epoch in range(20):\n",
        "  for i, (x,y) in enumerate(train_loader):\n",
        "    x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = loss(classifier(x), y)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Classifier_loss: {}'.format(epoch+1, 20, i+1, len(train_loader), train_loss.item()))"
      ],
      "id": "JRb-0G9590TS",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [1/469], Classifier_loss: 2.3045690059661865\n",
            "Epoch [1/20], Step [101/469], Classifier_loss: 0.7583668231964111\n",
            "Epoch [1/20], Step [201/469], Classifier_loss: 0.392402708530426\n",
            "Epoch [1/20], Step [301/469], Classifier_loss: 0.20682597160339355\n",
            "Epoch [1/20], Step [401/469], Classifier_loss: 0.19816024601459503\n",
            "Epoch [2/20], Step [1/469], Classifier_loss: 0.18145281076431274\n",
            "Epoch [2/20], Step [101/469], Classifier_loss: 0.1319606453180313\n",
            "Epoch [2/20], Step [201/469], Classifier_loss: 0.17492762207984924\n",
            "Epoch [2/20], Step [301/469], Classifier_loss: 0.13758894801139832\n",
            "Epoch [2/20], Step [401/469], Classifier_loss: 0.11321841925382614\n",
            "Epoch [3/20], Step [1/469], Classifier_loss: 0.10539592057466507\n",
            "Epoch [3/20], Step [101/469], Classifier_loss: 0.11800473183393478\n",
            "Epoch [3/20], Step [201/469], Classifier_loss: 0.1449347287416458\n",
            "Epoch [3/20], Step [301/469], Classifier_loss: 0.04362476244568825\n",
            "Epoch [3/20], Step [401/469], Classifier_loss: 0.07333600521087646\n",
            "Epoch [4/20], Step [1/469], Classifier_loss: 0.043253302574157715\n",
            "Epoch [4/20], Step [101/469], Classifier_loss: 0.035174526274204254\n",
            "Epoch [4/20], Step [201/469], Classifier_loss: 0.07704134285449982\n",
            "Epoch [4/20], Step [301/469], Classifier_loss: 0.028102947399020195\n",
            "Epoch [4/20], Step [401/469], Classifier_loss: 0.09790444374084473\n",
            "Epoch [5/20], Step [1/469], Classifier_loss: 0.026229817420244217\n",
            "Epoch [5/20], Step [101/469], Classifier_loss: 0.02239326201379299\n",
            "Epoch [5/20], Step [201/469], Classifier_loss: 0.03286638855934143\n",
            "Epoch [5/20], Step [301/469], Classifier_loss: 0.09230048209428787\n",
            "Epoch [5/20], Step [401/469], Classifier_loss: 0.03431481495499611\n",
            "Epoch [6/20], Step [1/469], Classifier_loss: 0.04858844727277756\n",
            "Epoch [6/20], Step [101/469], Classifier_loss: 0.019957810640335083\n",
            "Epoch [6/20], Step [201/469], Classifier_loss: 0.07304150611162186\n",
            "Epoch [6/20], Step [301/469], Classifier_loss: 0.06053991988301277\n",
            "Epoch [6/20], Step [401/469], Classifier_loss: 0.031009888276457787\n",
            "Epoch [7/20], Step [1/469], Classifier_loss: 0.022510627284646034\n",
            "Epoch [7/20], Step [101/469], Classifier_loss: 0.10015260428190231\n",
            "Epoch [7/20], Step [201/469], Classifier_loss: 0.03833992779254913\n",
            "Epoch [7/20], Step [301/469], Classifier_loss: 0.059267278760671616\n",
            "Epoch [7/20], Step [401/469], Classifier_loss: 0.02446099929511547\n",
            "Epoch [8/20], Step [1/469], Classifier_loss: 0.01765652932226658\n",
            "Epoch [8/20], Step [101/469], Classifier_loss: 0.045837998390197754\n",
            "Epoch [8/20], Step [201/469], Classifier_loss: 0.02016967535018921\n",
            "Epoch [8/20], Step [301/469], Classifier_loss: 0.04520585015416145\n",
            "Epoch [8/20], Step [401/469], Classifier_loss: 0.006687004119157791\n",
            "Epoch [9/20], Step [1/469], Classifier_loss: 0.03744486719369888\n",
            "Epoch [9/20], Step [101/469], Classifier_loss: 0.03174761310219765\n",
            "Epoch [9/20], Step [201/469], Classifier_loss: 0.04965610057115555\n",
            "Epoch [9/20], Step [301/469], Classifier_loss: 0.05472194403409958\n",
            "Epoch [9/20], Step [401/469], Classifier_loss: 0.03851822391152382\n",
            "Epoch [10/20], Step [1/469], Classifier_loss: 0.07067518681287766\n",
            "Epoch [10/20], Step [101/469], Classifier_loss: 0.08519977331161499\n",
            "Epoch [10/20], Step [201/469], Classifier_loss: 0.008733377791941166\n",
            "Epoch [10/20], Step [301/469], Classifier_loss: 0.006369657814502716\n",
            "Epoch [10/20], Step [401/469], Classifier_loss: 0.004632869269698858\n",
            "Epoch [11/20], Step [1/469], Classifier_loss: 0.03254793584346771\n",
            "Epoch [11/20], Step [101/469], Classifier_loss: 0.00436334777623415\n",
            "Epoch [11/20], Step [201/469], Classifier_loss: 0.010806825943291187\n",
            "Epoch [11/20], Step [301/469], Classifier_loss: 0.04127683863043785\n",
            "Epoch [11/20], Step [401/469], Classifier_loss: 0.017286982387304306\n",
            "Epoch [12/20], Step [1/469], Classifier_loss: 0.04058660939335823\n",
            "Epoch [12/20], Step [101/469], Classifier_loss: 0.023770544677972794\n",
            "Epoch [12/20], Step [201/469], Classifier_loss: 0.02462518960237503\n",
            "Epoch [12/20], Step [301/469], Classifier_loss: 0.0030581376049667597\n",
            "Epoch [12/20], Step [401/469], Classifier_loss: 0.011519147083163261\n",
            "Epoch [13/20], Step [1/469], Classifier_loss: 0.028074398636817932\n",
            "Epoch [13/20], Step [101/469], Classifier_loss: 0.02431543730199337\n",
            "Epoch [13/20], Step [201/469], Classifier_loss: 0.012457859702408314\n",
            "Epoch [13/20], Step [301/469], Classifier_loss: 0.029685823246836662\n",
            "Epoch [13/20], Step [401/469], Classifier_loss: 0.03546278178691864\n",
            "Epoch [14/20], Step [1/469], Classifier_loss: 0.0319705568253994\n",
            "Epoch [14/20], Step [101/469], Classifier_loss: 0.0005769753479398787\n",
            "Epoch [14/20], Step [201/469], Classifier_loss: 0.003172104014083743\n",
            "Epoch [14/20], Step [301/469], Classifier_loss: 0.0065878271125257015\n",
            "Epoch [14/20], Step [401/469], Classifier_loss: 0.0029408051632344723\n",
            "Epoch [15/20], Step [1/469], Classifier_loss: 0.02746005915105343\n",
            "Epoch [15/20], Step [101/469], Classifier_loss: 0.004813320003449917\n",
            "Epoch [15/20], Step [201/469], Classifier_loss: 0.021088918671011925\n",
            "Epoch [15/20], Step [301/469], Classifier_loss: 0.0058166636154055595\n",
            "Epoch [15/20], Step [401/469], Classifier_loss: 0.028091775253415108\n",
            "Epoch [16/20], Step [1/469], Classifier_loss: 0.004872746765613556\n",
            "Epoch [16/20], Step [101/469], Classifier_loss: 0.0008698740275576711\n",
            "Epoch [16/20], Step [201/469], Classifier_loss: 0.006006637122482061\n",
            "Epoch [16/20], Step [301/469], Classifier_loss: 0.006253332830965519\n",
            "Epoch [16/20], Step [401/469], Classifier_loss: 0.024145862087607384\n",
            "Epoch [17/20], Step [1/469], Classifier_loss: 0.0018426415044814348\n",
            "Epoch [17/20], Step [101/469], Classifier_loss: 0.02776198834180832\n",
            "Epoch [17/20], Step [201/469], Classifier_loss: 0.03702440857887268\n",
            "Epoch [17/20], Step [301/469], Classifier_loss: 0.009791768155992031\n",
            "Epoch [17/20], Step [401/469], Classifier_loss: 0.011295239441096783\n",
            "Epoch [18/20], Step [1/469], Classifier_loss: 0.01038809958845377\n",
            "Epoch [18/20], Step [101/469], Classifier_loss: 0.0016517923213541508\n",
            "Epoch [18/20], Step [201/469], Classifier_loss: 0.04433126002550125\n",
            "Epoch [18/20], Step [301/469], Classifier_loss: 0.0008655431447550654\n",
            "Epoch [18/20], Step [401/469], Classifier_loss: 0.00873939972370863\n",
            "Epoch [19/20], Step [1/469], Classifier_loss: 0.010958378203213215\n",
            "Epoch [19/20], Step [101/469], Classifier_loss: 0.017824621871113777\n",
            "Epoch [19/20], Step [201/469], Classifier_loss: 0.002486705081537366\n",
            "Epoch [19/20], Step [301/469], Classifier_loss: 0.0014728683745488524\n",
            "Epoch [19/20], Step [401/469], Classifier_loss: 0.022575484588742256\n",
            "Epoch [20/20], Step [1/469], Classifier_loss: 0.03957785293459892\n",
            "Epoch [20/20], Step [101/469], Classifier_loss: 0.00949326902627945\n",
            "Epoch [20/20], Step [201/469], Classifier_loss: 0.014396267011761665\n",
            "Epoch [20/20], Step [301/469], Classifier_loss: 0.008384017273783684\n",
            "Epoch [20/20], Step [401/469], Classifier_loss: 0.018143657594919205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3rS6hyACk6"
      },
      "source": [
        "torch.save(classifier.state_dict(), 'pretrained_classifier.pth')"
      ],
      "id": "rE3rS6hyACk6",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s-aPDV3ANLX"
      },
      "source": [
        "def accuracy(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for x,y in test_loader:\n",
        "          images, labels = x.cuda(), y.cuda()\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy: %s %%' % (100 * correct / total))"
      ],
      "id": "2s-aPDV3ANLX",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bC-zfNNJfTJ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    layers = [\n",
        "              nn.Conv2d(1, 64, 5, padding=2, stride=2), nn.BatchNorm2d(64, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Conv2d(64, 128, 5, padding=2, stride=2), nn.BatchNorm2d(128, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Conv2d(128, 256, 5, padding=2, stride=2), nn.BatchNorm2d(256, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Flatten(), nn.Linear(256*4*4, 2048), nn.BatchNorm1d(2048, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Linear(2048, 16),\n",
        "    ]\n",
        "    self.net = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "id": "3bC-zfNNJfTJ",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA7giZI2Eygz"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Sequential(\n",
        "              nn.Linear(16, 256*4*4), nn.BatchNorm1d(256*4*4, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              )\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256,256,6, stride=2, padding=2), nn.BatchNorm2d(256, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(256,128,6, stride=2, padding=2), nn.BatchNorm2d(128, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(128,32,6, stride=2, padding=3), nn.BatchNorm2d(32, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(32,1,5, stride=1, padding=3), nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = x.view(-1, 256, 4, 4)\n",
        "    return self.conv(x)"
      ],
      "id": "HA7giZI2Eygz",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz0kOY4sJp58"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, epsilon):\n",
        "    super().__init__()\n",
        "    self.decoder = Decoder()\n",
        "    self.encoder = Encoder()\n",
        "    self.classifier = classifier\n",
        "    self.epsilon = epsilon\n",
        "    for param in classifier.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    z = self.encoder(x)\n",
        "    perturbation = epsilon * self.decoder(z)\n",
        "    predictions = F.softmax(self.classifier(x+perturbation),1)\n",
        "    return predictions.gather(1, y.view(-1,1)).mean(), perturbation"
      ],
      "id": "nz0kOY4sJp58",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uEIlGkFOxtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555bcecd-d9e4-411a-ac47-4031e798ae8e"
      },
      "source": [
        "epsilon = 0.1\n",
        "epochs = 5\n",
        "model = Generator(epsilon).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "for epoch in range(epochs):\n",
        "  for i, (x,y) in enumerate(train_loader):\n",
        "    x,y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    loss, perturbation = model.loss(x,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), loss.item()))"
      ],
      "id": "2uEIlGkFOxtG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [1/469], Loss: 0.9934682250022888\n",
            "Epoch [1/5], Step [101/469], Loss: 0.5766056776046753\n",
            "Epoch [1/5], Step [201/469], Loss: 0.5480083227157593\n",
            "Epoch [1/5], Step [301/469], Loss: 0.47168421745300293\n",
            "Epoch [1/5], Step [401/469], Loss: 0.4709986746311188\n",
            "Epoch [2/5], Step [1/469], Loss: 0.4014093279838562\n",
            "Epoch [2/5], Step [101/469], Loss: 0.36564743518829346\n",
            "Epoch [2/5], Step [201/469], Loss: 0.41835901141166687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxtK8wEX08j"
      },
      "source": [
        "def adv_accuracy(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for x,y in test_loader:\n",
        "          images, labels = x.cuda(), y.cuda()\n",
        "          outputs = net(model.loss(images, labels)[1] + images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Adversarial accuracy: %s %%' % (100 * correct / total))"
      ],
      "id": "cLxtK8wEX08j",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVhbhCXhNbah",
        "outputId": "987deb64-b5a7-45bd-b2bd-32318f312e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "adv_accuracy(classifier)"
      ],
      "id": "YVhbhCXhNbah",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy: 0.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXEqWcFazIX"
      },
      "source": [
        "baseClassifier = BaseClassifier().cuda()\n",
        "def train_base(device, train_loader):\n",
        "  classifier_optimizer = torch.optim.Adam(baseClassifier.parameters(), lr=1e-3)\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  for epoch in range(epochs):\n",
        "    for i, (x,y) in enumerate(train_loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      classifier_optimizer.zero_grad()\n",
        "      classifier_loss = loss(baseClassifier(x), y) \n",
        "      classifier_loss.backward()\n",
        "      classifier_optimizer.step()      \n",
        "      if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Classifier_loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), classifier_loss))\n"
      ],
      "id": "xKXEqWcFazIX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVcQif8YcHzg",
        "outputId": "2e8a840b-2f8b-4fa6-813a-7301a5a515fc"
      },
      "source": [
        "train_base(device, train_loader)"
      ],
      "id": "BVcQif8YcHzg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [1/469], Classifier_loss: 2.3021018505096436\n",
            "Epoch [1/10], Step [101/469], Classifier_loss: 2.016310214996338\n",
            "Epoch [1/10], Step [201/469], Classifier_loss: 2.084836959838867\n",
            "Epoch [1/10], Step [301/469], Classifier_loss: 1.9202932119369507\n",
            "Epoch [1/10], Step [401/469], Classifier_loss: 1.9438130855560303\n",
            "Epoch [2/10], Step [1/469], Classifier_loss: 2.002037286758423\n",
            "Epoch [2/10], Step [101/469], Classifier_loss: 1.9903645515441895\n",
            "Epoch [2/10], Step [201/469], Classifier_loss: 1.9259456396102905\n",
            "Epoch [2/10], Step [301/469], Classifier_loss: 1.836113452911377\n",
            "Epoch [2/10], Step [401/469], Classifier_loss: 1.8242815732955933\n",
            "Epoch [3/10], Step [1/469], Classifier_loss: 1.850592851638794\n",
            "Epoch [3/10], Step [101/469], Classifier_loss: 1.8252578973770142\n",
            "Epoch [3/10], Step [201/469], Classifier_loss: 1.8615632057189941\n",
            "Epoch [3/10], Step [301/469], Classifier_loss: 1.8342620134353638\n",
            "Epoch [3/10], Step [401/469], Classifier_loss: 1.7241915464401245\n",
            "Epoch [4/10], Step [1/469], Classifier_loss: 1.8271490335464478\n",
            "Epoch [4/10], Step [101/469], Classifier_loss: 1.7574673891067505\n",
            "Epoch [4/10], Step [201/469], Classifier_loss: 1.7474403381347656\n",
            "Epoch [4/10], Step [301/469], Classifier_loss: 1.7865614891052246\n",
            "Epoch [4/10], Step [401/469], Classifier_loss: 1.672484278678894\n",
            "Epoch [5/10], Step [1/469], Classifier_loss: 1.6818642616271973\n",
            "Epoch [5/10], Step [101/469], Classifier_loss: 1.664484977722168\n",
            "Epoch [5/10], Step [201/469], Classifier_loss: 1.6624696254730225\n",
            "Epoch [5/10], Step [301/469], Classifier_loss: 1.6695024967193604\n",
            "Epoch [5/10], Step [401/469], Classifier_loss: 1.666835904121399\n",
            "Epoch [6/10], Step [1/469], Classifier_loss: 1.6487090587615967\n",
            "Epoch [6/10], Step [101/469], Classifier_loss: 1.6422077417373657\n",
            "Epoch [6/10], Step [201/469], Classifier_loss: 1.6621836423873901\n",
            "Epoch [6/10], Step [301/469], Classifier_loss: 1.6836382150650024\n",
            "Epoch [6/10], Step [401/469], Classifier_loss: 1.6233028173446655\n",
            "Epoch [7/10], Step [1/469], Classifier_loss: 1.7239229679107666\n",
            "Epoch [7/10], Step [101/469], Classifier_loss: 1.6853944063186646\n",
            "Epoch [7/10], Step [201/469], Classifier_loss: 1.6467400789260864\n",
            "Epoch [7/10], Step [301/469], Classifier_loss: 1.6634594202041626\n",
            "Epoch [7/10], Step [401/469], Classifier_loss: 1.683746337890625\n",
            "Epoch [8/10], Step [1/469], Classifier_loss: 1.6611547470092773\n",
            "Epoch [8/10], Step [101/469], Classifier_loss: 1.6921091079711914\n",
            "Epoch [8/10], Step [201/469], Classifier_loss: 1.738488793373108\n",
            "Epoch [8/10], Step [301/469], Classifier_loss: 1.668574333190918\n",
            "Epoch [8/10], Step [401/469], Classifier_loss: 1.6360399723052979\n",
            "Epoch [9/10], Step [1/469], Classifier_loss: 1.6585856676101685\n",
            "Epoch [9/10], Step [101/469], Classifier_loss: 1.6423945426940918\n",
            "Epoch [9/10], Step [201/469], Classifier_loss: 1.6684439182281494\n",
            "Epoch [9/10], Step [301/469], Classifier_loss: 1.7060238122940063\n",
            "Epoch [9/10], Step [401/469], Classifier_loss: 1.641737937927246\n",
            "Epoch [10/10], Step [1/469], Classifier_loss: 1.6136471033096313\n",
            "Epoch [10/10], Step [101/469], Classifier_loss: 1.5822993516921997\n",
            "Epoch [10/10], Step [201/469], Classifier_loss: 1.5842385292053223\n",
            "Epoch [10/10], Step [301/469], Classifier_loss: 1.548482894897461\n",
            "Epoch [10/10], Step [401/469], Classifier_loss: 1.6150031089782715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLCllOEOdcVa"
      },
      "source": [
        "base_classifier_loss  = 0\n",
        "adv_classifier_loss = 0 \n",
        "loss = nn.CrossEntropyLoss()\n",
        "for x,y in test_loader:\n",
        "  x,y = x.to(device), y.to(device)\n",
        "  perturbation = generator(x)\n",
        "  perturbed_image = x + perturbation\n",
        "  base_classifier_loss += loss(baseClassifier(x), y)\n",
        "  adv_classifier_loss += loss(classifier(x), y)"
      ],
      "id": "PLCllOEOdcVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHAhdVzfeGKm",
        "outputId": "b028707d-4def-4c26-819f-6d0f41e56990"
      },
      "source": [
        "print(\"Adversarial classifier loss: \", adv_classifier_loss.detach().cpu().numpy(), \"||| Base classifier loss: \", base_classifier_loss.detach().cpu().numpy())"
      ],
      "id": "IHAhdVzfeGKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial classifier loss:  117.13299 ||| Base classifier loss:  124.39505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbDHCKljev37"
      },
      "source": [
        "Now, let's take random samples from the test set and inspect their behavior under adversarial perturbations. "
      ],
      "id": "hbDHCKljev37"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3FPqtluze9vX",
        "outputId": "20b982fb-e16a-4736-f877-33a4a5203d7b"
      },
      "source": [
        "#To see the adversarial examples, choose the index from [3, 10, 13, 18]\n",
        "i = 3\n",
        "for x, y in test_loader:\n",
        "  x,y = x.to(device), y.to(device)\n",
        "  perturbation = generator(x)\n",
        "  perturbed_image = x + perturbation\n",
        "  base_pred = baseClassifier(perturbed_image)\n",
        "  adv_pred = classifier(perturbed_image)\n",
        "\n",
        "  image = (perturbed_image).detach().cpu().numpy()\n",
        "  original = x[i][0].cpu().numpy()\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.show()\n",
        "  plt.imshow(original, cmap='gray')\n",
        "  plt.show()\n",
        "  plt.imshow((image-original)[i][0]) #perturbation visualization\n",
        "  plt.show()\n",
        "  print(np.linalg.norm((image-original)[i][0], ord=2))\n",
        "  print(torch.max(base_pred.data,1))\n",
        "  print(torch.max(adv_pred.data,1))\n",
        "  print(y)\n",
        "  break\n",
        "\n",
        "\n",
        "  i+=1\n"
      ],
      "id": "3FPqtluze9vX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.016742798\n",
            "torch.return_types.max(\n",
            "values=tensor([1.0000, 1.0000, 1.0000, 0.9995, 1.0000, 1.0000, 1.0000, 0.9727, 0.9996,\n",
            "        1.0000, 0.5967, 1.0000, 1.0000, 0.6286, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.9925, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9987, 0.9999,\n",
            "        1.0000, 0.9890, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9996, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 0.9795, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9219,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 0.6922,\n",
            "        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 0.9065, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9993,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9297, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 0.9961, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.9948, 1.0000], device='cuda:0'),\n",
            "indices=tensor([7, 2, 1, 6, 4, 1, 4, 9, 5, 9, 8, 6, 9, 8, 1, 5, 9, 7, 5, 4, 9, 6, 6, 5,\n",
            "        4, 6, 7, 4, 8, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
            "        4, 4, 6, 3, 5, 5, 6, 8, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 5, 7, 8,\n",
            "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
            "        1, 7, 6, 9, 6, 6, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 9, 4, 4, 9, 2,\n",
            "        5, 4, 7, 6, 7, 9, 5, 5], device='cuda:0'))\n",
            "torch.return_types.max(\n",
            "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.9979, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9741,\n",
            "        1.0000, 1.0000, 1.0000, 0.9963, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 0.9986, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9822, 0.9935, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9890, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 0.9994, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000], device='cuda:0'),\n",
            "indices=tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
            "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
            "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 0, 4, 3, 0, 7, 0,\n",
            "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
            "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 9, 4, 4, 9, 2,\n",
            "        5, 4, 7, 6, 7, 9, 0, 5], device='cuda:0'))\n",
            "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
            "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
            "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
            "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
            "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
            "        5, 4, 7, 6, 7, 9, 0, 5], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMvn3oN9kqvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d133c48d-864a-4fd7-bff2-8857de69bbfb"
      },
      "source": [
        "total = 0\n",
        "base_correct = 0\n",
        "adv_correct = 0\n",
        "for x, y in test_loader:\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  perturbation = generator(x)\n",
        "  perturbed_image = x + perturbation\n",
        "\n",
        "  base_out = baseClassifier(perturbed_image)\n",
        "  adv_out = classifier(perturbed_image)\n",
        "  _, base_pred = torch.max(base_out.data, 1)\n",
        "  _, adv_pred = torch.max(adv_out.data, 1)\n",
        "  total += y.size(0)\n",
        "  adv_correct += (adv_pred == y).sum().item()\n",
        "  base_correct += (base_pred == y).sum().item()\n",
        "\n",
        "print(\"Adversarially trained network's accuracy:\", adv_correct/total, \"Base network's accuracy:\", base_correct/total)"
      ],
      "id": "XMvn3oN9kqvu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarially trained network's accuracy: 0.9782 Base network's accuracy: 0.8843\n"
          ]
        }
      ]
    }
  ]
}