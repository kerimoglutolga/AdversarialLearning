{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FGSM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uiflfa3DbKn"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np "
      ],
      "id": "1uiflfa3DbKn",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-wealth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4f5e35-5fd6-4a2c-dca4-dc44075e8992"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "train_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=True\n",
        ")\n",
        "\n",
        "test_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=False\n",
        ")"
      ],
      "id": "behind-wealth",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 07:30:41--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-10-09 07:30:41--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [       <=>          ]  33.20M  25.7MB/s    in 1.3s    \n",
            "\n",
            "2021-10-09 07:30:42 (25.7 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vertical-venice"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=128, shuffle=False)"
      ],
      "id": "vertical-venice",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJQc2XkDLa04"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 96, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=1, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 10, kernel_size=1), \n",
        "        nn.AvgPool2d(kernel_size=8),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = self.net(x)\n",
        "    return logits.view(-1, 10)"
      ],
      "id": "LJQc2XkDLa04",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRb-0G9590TS",
        "outputId": "42b35c07-78f2-4c0c-bc9c-77c78a463710"
      },
      "source": [
        "# Pretrain classifier\n",
        "classifier = Classifier().cuda()\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "for epoch in range(20):\n",
        "  for i, (x,y) in enumerate(train_loader):\n",
        "    x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = loss(classifier(x), y)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Classifier_loss: {}'.format(epoch+1, 20, i+1, len(train_loader), train_loss.item()))"
      ],
      "id": "JRb-0G9590TS",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [1/469], Classifier_loss: 2.3045690059661865\n",
            "Epoch [1/20], Step [101/469], Classifier_loss: 0.7583668231964111\n",
            "Epoch [1/20], Step [201/469], Classifier_loss: 0.392402708530426\n",
            "Epoch [1/20], Step [301/469], Classifier_loss: 0.20682597160339355\n",
            "Epoch [1/20], Step [401/469], Classifier_loss: 0.19816024601459503\n",
            "Epoch [2/20], Step [1/469], Classifier_loss: 0.18145281076431274\n",
            "Epoch [2/20], Step [101/469], Classifier_loss: 0.1319606453180313\n",
            "Epoch [2/20], Step [201/469], Classifier_loss: 0.17492762207984924\n",
            "Epoch [2/20], Step [301/469], Classifier_loss: 0.13758894801139832\n",
            "Epoch [2/20], Step [401/469], Classifier_loss: 0.11321841925382614\n",
            "Epoch [3/20], Step [1/469], Classifier_loss: 0.10539592057466507\n",
            "Epoch [3/20], Step [101/469], Classifier_loss: 0.11800473183393478\n",
            "Epoch [3/20], Step [201/469], Classifier_loss: 0.1449347287416458\n",
            "Epoch [3/20], Step [301/469], Classifier_loss: 0.04362476244568825\n",
            "Epoch [3/20], Step [401/469], Classifier_loss: 0.07333600521087646\n",
            "Epoch [4/20], Step [1/469], Classifier_loss: 0.043253302574157715\n",
            "Epoch [4/20], Step [101/469], Classifier_loss: 0.035174526274204254\n",
            "Epoch [4/20], Step [201/469], Classifier_loss: 0.07704134285449982\n",
            "Epoch [4/20], Step [301/469], Classifier_loss: 0.028102947399020195\n",
            "Epoch [4/20], Step [401/469], Classifier_loss: 0.09790444374084473\n",
            "Epoch [5/20], Step [1/469], Classifier_loss: 0.026229817420244217\n",
            "Epoch [5/20], Step [101/469], Classifier_loss: 0.02239326201379299\n",
            "Epoch [5/20], Step [201/469], Classifier_loss: 0.03286638855934143\n",
            "Epoch [5/20], Step [301/469], Classifier_loss: 0.09230048209428787\n",
            "Epoch [5/20], Step [401/469], Classifier_loss: 0.03431481495499611\n",
            "Epoch [6/20], Step [1/469], Classifier_loss: 0.04858844727277756\n",
            "Epoch [6/20], Step [101/469], Classifier_loss: 0.019957810640335083\n",
            "Epoch [6/20], Step [201/469], Classifier_loss: 0.07304150611162186\n",
            "Epoch [6/20], Step [301/469], Classifier_loss: 0.06053991988301277\n",
            "Epoch [6/20], Step [401/469], Classifier_loss: 0.031009888276457787\n",
            "Epoch [7/20], Step [1/469], Classifier_loss: 0.022510627284646034\n",
            "Epoch [7/20], Step [101/469], Classifier_loss: 0.10015260428190231\n",
            "Epoch [7/20], Step [201/469], Classifier_loss: 0.03833992779254913\n",
            "Epoch [7/20], Step [301/469], Classifier_loss: 0.059267278760671616\n",
            "Epoch [7/20], Step [401/469], Classifier_loss: 0.02446099929511547\n",
            "Epoch [8/20], Step [1/469], Classifier_loss: 0.01765652932226658\n",
            "Epoch [8/20], Step [101/469], Classifier_loss: 0.045837998390197754\n",
            "Epoch [8/20], Step [201/469], Classifier_loss: 0.02016967535018921\n",
            "Epoch [8/20], Step [301/469], Classifier_loss: 0.04520585015416145\n",
            "Epoch [8/20], Step [401/469], Classifier_loss: 0.006687004119157791\n",
            "Epoch [9/20], Step [1/469], Classifier_loss: 0.03744486719369888\n",
            "Epoch [9/20], Step [101/469], Classifier_loss: 0.03174761310219765\n",
            "Epoch [9/20], Step [201/469], Classifier_loss: 0.04965610057115555\n",
            "Epoch [9/20], Step [301/469], Classifier_loss: 0.05472194403409958\n",
            "Epoch [9/20], Step [401/469], Classifier_loss: 0.03851822391152382\n",
            "Epoch [10/20], Step [1/469], Classifier_loss: 0.07067518681287766\n",
            "Epoch [10/20], Step [101/469], Classifier_loss: 0.08519977331161499\n",
            "Epoch [10/20], Step [201/469], Classifier_loss: 0.008733377791941166\n",
            "Epoch [10/20], Step [301/469], Classifier_loss: 0.006369657814502716\n",
            "Epoch [10/20], Step [401/469], Classifier_loss: 0.004632869269698858\n",
            "Epoch [11/20], Step [1/469], Classifier_loss: 0.03254793584346771\n",
            "Epoch [11/20], Step [101/469], Classifier_loss: 0.00436334777623415\n",
            "Epoch [11/20], Step [201/469], Classifier_loss: 0.010806825943291187\n",
            "Epoch [11/20], Step [301/469], Classifier_loss: 0.04127683863043785\n",
            "Epoch [11/20], Step [401/469], Classifier_loss: 0.017286982387304306\n",
            "Epoch [12/20], Step [1/469], Classifier_loss: 0.04058660939335823\n",
            "Epoch [12/20], Step [101/469], Classifier_loss: 0.023770544677972794\n",
            "Epoch [12/20], Step [201/469], Classifier_loss: 0.02462518960237503\n",
            "Epoch [12/20], Step [301/469], Classifier_loss: 0.0030581376049667597\n",
            "Epoch [12/20], Step [401/469], Classifier_loss: 0.011519147083163261\n",
            "Epoch [13/20], Step [1/469], Classifier_loss: 0.028074398636817932\n",
            "Epoch [13/20], Step [101/469], Classifier_loss: 0.02431543730199337\n",
            "Epoch [13/20], Step [201/469], Classifier_loss: 0.012457859702408314\n",
            "Epoch [13/20], Step [301/469], Classifier_loss: 0.029685823246836662\n",
            "Epoch [13/20], Step [401/469], Classifier_loss: 0.03546278178691864\n",
            "Epoch [14/20], Step [1/469], Classifier_loss: 0.0319705568253994\n",
            "Epoch [14/20], Step [101/469], Classifier_loss: 0.0005769753479398787\n",
            "Epoch [14/20], Step [201/469], Classifier_loss: 0.003172104014083743\n",
            "Epoch [14/20], Step [301/469], Classifier_loss: 0.0065878271125257015\n",
            "Epoch [14/20], Step [401/469], Classifier_loss: 0.0029408051632344723\n",
            "Epoch [15/20], Step [1/469], Classifier_loss: 0.02746005915105343\n",
            "Epoch [15/20], Step [101/469], Classifier_loss: 0.004813320003449917\n",
            "Epoch [15/20], Step [201/469], Classifier_loss: 0.021088918671011925\n",
            "Epoch [15/20], Step [301/469], Classifier_loss: 0.0058166636154055595\n",
            "Epoch [15/20], Step [401/469], Classifier_loss: 0.028091775253415108\n",
            "Epoch [16/20], Step [1/469], Classifier_loss: 0.004872746765613556\n",
            "Epoch [16/20], Step [101/469], Classifier_loss: 0.0008698740275576711\n",
            "Epoch [16/20], Step [201/469], Classifier_loss: 0.006006637122482061\n",
            "Epoch [16/20], Step [301/469], Classifier_loss: 0.006253332830965519\n",
            "Epoch [16/20], Step [401/469], Classifier_loss: 0.024145862087607384\n",
            "Epoch [17/20], Step [1/469], Classifier_loss: 0.0018426415044814348\n",
            "Epoch [17/20], Step [101/469], Classifier_loss: 0.02776198834180832\n",
            "Epoch [17/20], Step [201/469], Classifier_loss: 0.03702440857887268\n",
            "Epoch [17/20], Step [301/469], Classifier_loss: 0.009791768155992031\n",
            "Epoch [17/20], Step [401/469], Classifier_loss: 0.011295239441096783\n",
            "Epoch [18/20], Step [1/469], Classifier_loss: 0.01038809958845377\n",
            "Epoch [18/20], Step [101/469], Classifier_loss: 0.0016517923213541508\n",
            "Epoch [18/20], Step [201/469], Classifier_loss: 0.04433126002550125\n",
            "Epoch [18/20], Step [301/469], Classifier_loss: 0.0008655431447550654\n",
            "Epoch [18/20], Step [401/469], Classifier_loss: 0.00873939972370863\n",
            "Epoch [19/20], Step [1/469], Classifier_loss: 0.010958378203213215\n",
            "Epoch [19/20], Step [101/469], Classifier_loss: 0.017824621871113777\n",
            "Epoch [19/20], Step [201/469], Classifier_loss: 0.002486705081537366\n",
            "Epoch [19/20], Step [301/469], Classifier_loss: 0.0014728683745488524\n",
            "Epoch [19/20], Step [401/469], Classifier_loss: 0.022575484588742256\n",
            "Epoch [20/20], Step [1/469], Classifier_loss: 0.03957785293459892\n",
            "Epoch [20/20], Step [101/469], Classifier_loss: 0.00949326902627945\n",
            "Epoch [20/20], Step [201/469], Classifier_loss: 0.014396267011761665\n",
            "Epoch [20/20], Step [301/469], Classifier_loss: 0.008384017273783684\n",
            "Epoch [20/20], Step [401/469], Classifier_loss: 0.018143657594919205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3rS6hyACk6"
      },
      "source": [
        "torch.save(classifier.state_dict(), 'pretrained_classifier.pth')"
      ],
      "id": "rE3rS6hyACk6",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s-aPDV3ANLX"
      },
      "source": [
        "def accuracy(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for x,y in test_loader:\n",
        "          images, labels = x.cuda(), y.cuda()\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy: %s %%' % (100 * correct / total))"
      ],
      "id": "2s-aPDV3ANLX",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bC-zfNNJfTJ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    layers = [\n",
        "              nn.Conv2d(1, 64, 5, padding=2, stride=2), nn.BatchNorm2d(64, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Conv2d(64, 128, 5, padding=2, stride=2), nn.BatchNorm2d(128, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Conv2d(128, 256, 5, padding=2, stride=2), nn.BatchNorm2d(256, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Flatten(), nn.Linear(256*4*4, 2048), nn.BatchNorm1d(2048, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              nn.Linear(2048, 16),\n",
        "    ]\n",
        "    self.net = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "id": "3bC-zfNNJfTJ",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA7giZI2Eygz"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Sequential(\n",
        "              nn.Linear(16, 256*4*4), nn.BatchNorm1d(256*4*4, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "              )\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256,256,6, stride=2, padding=2), nn.BatchNorm2d(256, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(256,128,6, stride=2, padding=2), nn.BatchNorm2d(128, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(128,32,6, stride=2, padding=3), nn.BatchNorm2d(32, momentum=0.9), nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(32,1,5, stride=1, padding=3), nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = x.view(-1, 256, 4, 4)\n",
        "    return self.conv(x)"
      ],
      "id": "HA7giZI2Eygz",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz0kOY4sJp58"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, epsilon):\n",
        "    super().__init__()\n",
        "    self.decoder = Decoder()\n",
        "    self.encoder = Encoder()\n",
        "    self.classifier = classifier\n",
        "    self.epsilon = epsilon\n",
        "    for param in classifier.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    z = self.encoder(x)\n",
        "    perturbation = epsilon * self.decoder(z)\n",
        "    predictions = F.softmax(self.classifier(x+perturbation),1)\n",
        "    return predictions.gather(1, y.view(-1,1)).mean(), perturbation"
      ],
      "id": "nz0kOY4sJp58",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uEIlGkFOxtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555bcecd-d9e4-411a-ac47-4031e798ae8e"
      },
      "source": [
        "epsilon = 0.1\n",
        "epochs = 5\n",
        "model = Generator(epsilon).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "for epoch in range(epochs):\n",
        "  for i, (x,y) in enumerate(train_loader):\n",
        "    x,y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    loss, perturbation = model.loss(x,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), loss.item()))"
      ],
      "id": "2uEIlGkFOxtG",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [1/469], Loss: 0.9934682250022888\n",
            "Epoch [1/5], Step [101/469], Loss: 0.5766056776046753\n",
            "Epoch [1/5], Step [201/469], Loss: 0.5480083227157593\n",
            "Epoch [1/5], Step [301/469], Loss: 0.47168421745300293\n",
            "Epoch [1/5], Step [401/469], Loss: 0.4709986746311188\n",
            "Epoch [2/5], Step [1/469], Loss: 0.4014093279838562\n",
            "Epoch [2/5], Step [101/469], Loss: 0.36564743518829346\n",
            "Epoch [2/5], Step [201/469], Loss: 0.41835901141166687\n",
            "Epoch [2/5], Step [301/469], Loss: 0.5272511839866638\n",
            "Epoch [2/5], Step [401/469], Loss: 0.3643738627433777\n",
            "Epoch [3/5], Step [1/469], Loss: 0.4104117155075073\n",
            "Epoch [3/5], Step [101/469], Loss: 0.38611888885498047\n",
            "Epoch [3/5], Step [201/469], Loss: 0.38565725088119507\n",
            "Epoch [3/5], Step [301/469], Loss: 0.3670632541179657\n",
            "Epoch [3/5], Step [401/469], Loss: 0.4093725085258484\n",
            "Epoch [4/5], Step [1/469], Loss: 0.3694334030151367\n",
            "Epoch [4/5], Step [101/469], Loss: 0.36508655548095703\n",
            "Epoch [4/5], Step [201/469], Loss: 0.3823598027229309\n",
            "Epoch [4/5], Step [301/469], Loss: 0.2940019965171814\n",
            "Epoch [4/5], Step [401/469], Loss: 0.33775854110717773\n",
            "Epoch [5/5], Step [1/469], Loss: 0.35437431931495667\n",
            "Epoch [5/5], Step [101/469], Loss: 0.3405402898788452\n",
            "Epoch [5/5], Step [201/469], Loss: 0.2638537883758545\n",
            "Epoch [5/5], Step [301/469], Loss: 0.3138614594936371\n",
            "Epoch [5/5], Step [401/469], Loss: 0.3650328516960144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxtK8wEX08j"
      },
      "source": [
        "def adv_accuracy(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for x,y in test_loader:\n",
        "          images, labels = x.cuda(), y.cuda()\n",
        "          outputs = net(model.loss(images, labels)[1] + images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Adversarial accuracy: %s %%' % (100 * correct / total))"
      ],
      "id": "cLxtK8wEX08j",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVhbhCXhNbah",
        "outputId": "d3b7c1bd-8a64-444d-ca93-00d575b10322"
      },
      "source": [
        "adv_accuracy(classifier)"
      ],
      "id": "YVhbhCXhNbah",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy: 33.48 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbDHCKljev37"
      },
      "source": [
        "Now, let's take random samples from the test set and inspect their behavior under adversarial perturbations. "
      ],
      "id": "hbDHCKljev37"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FPqtluze9vX"
      },
      "source": [
        "iterator = iter(test_loader)\n",
        "x,y = next(iterator)\n",
        "x, y = x.cuda(), y.cuda()\n",
        "_, perturbations = model.loss(x,y)\n",
        "fig, axs = plt.subplots(64, 3)\n",
        "fig.suptitle('Comparisons')\n",
        "fig.set_figheight(100)\n",
        "fig.set_figwidth(10)\n",
        "images = []\n",
        "for i in range(64):\n",
        "        image, perturbation = x[i][0].cpu().detach().numpy(), perturbations[i][0].cpu().detach().numpy()\n",
        "        images.append(axs[i, 0].imshow(image, cmap='gray'))\n",
        "        images.append(axs[i,1].imshow(image+perturbation, cmap='gray'))\n",
        "        images.append(axs[i,2].imshow(perturbation, cmap='gray'))\n",
        "        axs[i, j].label_outer()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3FPqtluze9vX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMvn3oN9kqvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d133c48d-864a-4fd7-bff2-8857de69bbfb"
      },
      "source": [
        "total = 0\n",
        "base_correct = 0\n",
        "adv_correct = 0\n",
        "for x, y in test_loader:\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  perturbation = generator(x)\n",
        "  perturbed_image = x + perturbation\n",
        "\n",
        "  base_out = baseClassifier(perturbed_image)\n",
        "  adv_out = classifier(perturbed_image)\n",
        "  _, base_pred = torch.max(base_out.data, 1)\n",
        "  _, adv_pred = torch.max(adv_out.data, 1)\n",
        "  total += y.size(0)\n",
        "  adv_correct += (adv_pred == y).sum().item()\n",
        "  base_correct += (base_pred == y).sum().item()\n",
        "\n",
        "print(\"Adversarially trained network's accuracy:\", adv_correct/total, \"Base network's accuracy:\", base_correct/total)"
      ],
      "id": "XMvn3oN9kqvu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarially trained network's accuracy: 0.9782 Base network's accuracy: 0.8843\n"
          ]
        }
      ]
    }
  ]
}