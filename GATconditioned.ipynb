{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GATconditioned.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJcm160yRVcTUlnPZu6v9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerimoglutolga/AdversarialLearning/blob/master/GATconditioned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KssbejInr7TO"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPho-djehtf9"
      },
      "source": [
        "Not working conditioned GAT implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2KW-3PMsHvi",
        "outputId": "6cb23f3d-f1cc-4d99-c641-f07f42a7527e"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "train_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=True\n",
        ")\n",
        "\n",
        "test_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=False\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-04 16:09:08--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-10-04 16:09:09--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [             <=>    ]  33.20M  11.1MB/s    in 3.0s    \n",
            "\n",
            "2021-10-04 16:09:12 (11.1 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRufF7gmsIXq"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=128, shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdo-YARhs0el"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "       \n",
        "        self.add_conditions = nn.Sequential(\n",
        "        nn.Linear(28*28 + 10, 256), nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(256, 784), nn.LeakyReLU(0.2, inplace=True),    \n",
        "        )\n",
        "        self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 1, kernel_size=1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # Concatenate label embedding and image to produce input\n",
        "        img = torch.cat((x.view(x.size(0), -1),   self.label_emb(labels)), -1)\n",
        "        img = self.add_conditions(img)\n",
        "        img = img.view(img.size(0),1, 28,28)\n",
        "        img = self.net(img)\n",
        "        return img\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyOjIK43yJWT"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.label_emb = nn.Embedding(10, 10)\n",
        "    self.add_conditions = nn.Sequential(\n",
        "      nn.Linear(28*28 + 10, 256), nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Linear(256, 784), nn.LeakyReLU(0.2, inplace=True),    \n",
        "    )\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 96, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=1, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 10, kernel_size=1), \n",
        "        nn.AvgPool2d(kernel_size=8),\n",
        "    )\n",
        "  def forward(self, x, labels):\n",
        "    img = torch.cat((x.view(x.size(0), -1),   self.label_emb(labels)), -1)\n",
        "    img = self.add_conditions(img)\n",
        "    img = img.view(img.size(0), 1, 28,28)\n",
        "    img = self.net(img)\n",
        "    logits = F.softmax(img, dim=1)\n",
        "    return logits.view(-1, 10)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESOhqAWIycPy"
      },
      "source": [
        "epochs = 20\n",
        "epsilon = 0.1\n",
        "alpha = 0.5\n",
        "cg = 0.5\n",
        "k = 1\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor \n",
        "LongTensor = torch.cuda.LongTensor \n",
        "\n",
        "generator = Generator().cuda()\n",
        "classifier = Classifier().cuda()\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "# Standard (non-adversarial) training loop\n",
        "def train(device, train_loader):\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-6)\n",
        "  classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  for epoch in range(epochs):\n",
        "    for i, (x,y) in enumerate(train_loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      valid = Variable(FloatTensor(y.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "      fake = Variable(FloatTensor(y.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "\n",
        "      gen_labels = Variable(LongTensor(np.random.randint(0, 10, y.size(0))))\n",
        "      \n",
        "    \n",
        "      generator_optimizer.zero_grad()\n",
        "      perturbation = generator(x, gen_labels)\n",
        "      probs = F.softmax(classifier(x + perturbation, gen_labels), dim=1)\n",
        "      batch_loss = probs + cg * torch.norm(perturbation, p=2)\n",
        "      validity_loss = loss(probs, gen_labels)\n",
        "      gen_loss = 0.5*batch_loss.mean() + 0.5*validity_loss\n",
        "      gen_loss.backward()\n",
        "      generator_optimizer.step()\n",
        "\n",
        "      \"\"\"try:\n",
        "        x, y = next(train_loader_iter)\n",
        "      except StopIteration:\n",
        "        train_loader_iter = iter(train_loader)\n",
        "        x, y = next(train_loader_iter)\n",
        "      x,y = x.to(device), y.to(device)\"\"\"\n",
        "      classifier_optimizer.zero_grad()\n",
        "      perturbation = generator(x, gen_labels)\n",
        "      classifier_loss = alpha * loss(classifier(x, gen_labels), y) + (1-alpha) * loss(classifier(x+perturbation, gen_labels), y) + loss(classifier(x+perturbation, gen_labels), gen_labels)\n",
        "      classifier_loss.backward()\n",
        "      classifier_optimizer.step()      \n",
        "      if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Generator_loss: {}, Classifier_loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), gen_loss, classifier_loss))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW2-u3DBNW4L",
        "outputId": "9870a620-7406-4075-f118-4a5f28c93c69"
      },
      "source": [
        "train(device, train_loader) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [1/469], Generator_loss: 4.143485069274902, Classifier_loss: 4.606149673461914\n",
            "Epoch [1/20], Step [101/469], Generator_loss: 3.985125780105591, Classifier_loss: 4.429206848144531\n",
            "Epoch [1/20], Step [201/469], Generator_loss: 3.792543411254883, Classifier_loss: 4.113734722137451\n",
            "Epoch [1/20], Step [301/469], Generator_loss: 3.6108622550964355, Classifier_loss: 3.958320140838623\n",
            "Epoch [1/20], Step [401/469], Generator_loss: 3.4179959297180176, Classifier_loss: 3.8912816047668457\n",
            "Epoch [2/20], Step [1/469], Generator_loss: 3.2792956829071045, Classifier_loss: 3.807438850402832\n",
            "Epoch [2/20], Step [101/469], Generator_loss: 3.039543628692627, Classifier_loss: 3.753206253051758\n",
            "Epoch [2/20], Step [201/469], Generator_loss: 2.744701385498047, Classifier_loss: 3.7376179695129395\n",
            "Epoch [2/20], Step [301/469], Generator_loss: 2.3406949043273926, Classifier_loss: 3.683431625366211\n",
            "Epoch [2/20], Step [401/469], Generator_loss: 1.9438412189483643, Classifier_loss: 3.605470895767212\n",
            "Epoch [3/20], Step [1/469], Generator_loss: 1.796938180923462, Classifier_loss: 3.6347925662994385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxxOdWIyQg__",
        "outputId": "fa2a3547-cf99-4df5-a48e-eae5c7f25fe1"
      },
      "source": [
        "total = 0\n",
        "adv_correct = 0\n",
        "for x, y in test_loader:\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  gen_labels = Variable(LongTensor(np.random.randint(0, 10, y.size(0))))\n",
        "  perturbation = generator(x, gen_labels)\n",
        "  perturbed_image = x + perturbation\n",
        "\n",
        "  adv_out = classifier(perturbed_image, gen_labels)\n",
        "  _, adv_pred = torch.max(adv_out.data, 1)\n",
        "  total += y.size(0)\n",
        "  adv_correct += (adv_pred == y).sum().item()\n",
        "\n",
        "print(\"Adversarially trained network's accuracy:\", adv_correct/total)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarially trained network's accuracy: 0.0892\n"
          ]
        }
      ]
    }
  ]
}