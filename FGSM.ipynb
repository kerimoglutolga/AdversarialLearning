{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FGSM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uiflfa3DbKn"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np "
      ],
      "id": "1uiflfa3DbKn",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-wealth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d628022b-e35a-4e74-ce25-0d1e0e2b80b1"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "train_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=True\n",
        ")\n",
        "\n",
        "test_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=False\n",
        ")"
      ],
      "id": "behind-wealth",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-02 13:19:24--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-10-02 13:19:24--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [     <=>            ]  33.20M  35.4MB/s    in 0.9s    \n",
            "\n",
            "2021-10-02 13:19:25 (35.4 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vertical-venice"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=128, shuffle=False)"
      ],
      "id": "vertical-venice",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwUQXUuDEQ4t"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 1, kernel_size=1), nn.Tanh()\n",
        "        \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    perturbation = self.net(x)\n",
        "    return perturbation"
      ],
      "id": "OwUQXUuDEQ4t",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJQc2XkDLa04"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1, 48, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(48, 48, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(48, 96, kernel_size=3), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 96, kernel_size=1, stride=1, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(96, 10, kernel_size=1), \n",
        "        nn.AvgPool2d(kernel_size=8),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = F.softmax(self.net(x), dim=1)\n",
        "    return logits.view(-1, 10)"
      ],
      "id": "LJQc2XkDLa04",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bC-zfNNJfTJ"
      },
      "source": [
        "# HYPERPARAMETERS\n",
        "epochs = 10\n",
        "epsilon = 0.1\n",
        "alpha = 0.5\n",
        "cg = 0.5\n",
        "k = 1\n",
        "generator = Generator().cuda()\n",
        "classifier = Classifier().cuda()\n",
        "# Standard (non-adversarial) training loop\n",
        "def train(device, train_loader):\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-6)\n",
        "  classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  for epoch in range(epochs):\n",
        "    for i, (x,y) in enumerate(train_loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      generator_optimizer.zero_grad()\n",
        "      perturbation = generator(x)\n",
        "      probs = F.softmax(classifier(x + perturbation), dim=1)\n",
        "      batch_loss = probs + cg * torch.norm(perturbation, p=2)\n",
        "      gen_loss = batch_loss.mean()\n",
        "      gen_loss.backward()\n",
        "      generator_optimizer.step()\n",
        "\n",
        "      \"\"\"try:\n",
        "        x, y = next(train_loader_iter)\n",
        "      except StopIteration:\n",
        "        train_loader_iter = iter(train_loader)\n",
        "        x, y = next(train_loader_iter)\n",
        "      x,y = x.to(device), y.to(device)\"\"\"\n",
        "      classifier_optimizer.zero_grad()\n",
        "      perturbation = generator(x)\n",
        "      classifier_loss = alpha * loss(classifier(x), y) + (1-alpha) * loss(classifier(x+perturbation), y)\n",
        "      classifier_loss.backward()\n",
        "      classifier_optimizer.step()      \n",
        "      if (i%100 == 0):\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Generator_loss: {}, Classifier_loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), gen_loss, classifier_loss))\n"
      ],
      "id": "3bC-zfNNJfTJ",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz0kOY4sJp58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2e3696-fef5-47c8-b56b-76ee788e5886"
      },
      "source": [
        "train(device, train_loader) "
      ],
      "id": "nz0kOY4sJp58",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [1/469], Generator_loss: 3.378041982650757, Classifier_loss: 2.3027095794677734\n",
            "Epoch [1/10], Step [101/469], Generator_loss: 2.8898940086364746, Classifier_loss: 1.9934202432632446\n",
            "Epoch [1/10], Step [201/469], Generator_loss: 2.3850109577178955, Classifier_loss: 1.7614988088607788\n",
            "Epoch [1/10], Step [301/469], Generator_loss: 1.8578941822052002, Classifier_loss: 1.7886707782745361\n",
            "Epoch [1/10], Step [401/469], Generator_loss: 1.3481062650680542, Classifier_loss: 1.7943413257598877\n",
            "Epoch [2/10], Step [1/469], Generator_loss: 1.0729235410690308, Classifier_loss: 1.7833044528961182\n",
            "Epoch [2/10], Step [101/469], Generator_loss: 0.88849276304245, Classifier_loss: 1.727144718170166\n",
            "Epoch [2/10], Step [201/469], Generator_loss: 0.8230485916137695, Classifier_loss: 1.64340078830719\n",
            "Epoch [2/10], Step [301/469], Generator_loss: 0.7799439430236816, Classifier_loss: 1.67246413230896\n",
            "Epoch [2/10], Step [401/469], Generator_loss: 0.7412733435630798, Classifier_loss: 1.6787958145141602\n",
            "Epoch [3/10], Step [1/469], Generator_loss: 0.716545581817627, Classifier_loss: 1.7176132202148438\n",
            "Epoch [3/10], Step [101/469], Generator_loss: 0.679151713848114, Classifier_loss: 1.6439478397369385\n",
            "Epoch [3/10], Step [201/469], Generator_loss: 0.6365216970443726, Classifier_loss: 1.6169354915618896\n",
            "Epoch [3/10], Step [301/469], Generator_loss: 0.594780683517456, Classifier_loss: 1.6256396770477295\n",
            "Epoch [3/10], Step [401/469], Generator_loss: 0.5563846230506897, Classifier_loss: 1.5854039192199707\n",
            "Epoch [4/10], Step [1/469], Generator_loss: 0.5306048393249512, Classifier_loss: 1.5701324939727783\n",
            "Epoch [4/10], Step [101/469], Generator_loss: 0.49373140931129456, Classifier_loss: 1.61189866065979\n",
            "Epoch [4/10], Step [201/469], Generator_loss: 0.4570688307285309, Classifier_loss: 1.5416760444641113\n",
            "Epoch [4/10], Step [301/469], Generator_loss: 0.4218110144138336, Classifier_loss: 1.5780315399169922\n",
            "Epoch [4/10], Step [401/469], Generator_loss: 0.3873955309391022, Classifier_loss: 1.6107873916625977\n",
            "Epoch [5/10], Step [1/469], Generator_loss: 0.36353856325149536, Classifier_loss: 1.5180416107177734\n",
            "Epoch [5/10], Step [101/469], Generator_loss: 0.3314618766307831, Classifier_loss: 1.6538934707641602\n",
            "Epoch [5/10], Step [201/469], Generator_loss: 0.30182772874832153, Classifier_loss: 1.5432696342468262\n",
            "Epoch [5/10], Step [301/469], Generator_loss: 0.2741404175758362, Classifier_loss: 1.5671675205230713\n",
            "Epoch [5/10], Step [401/469], Generator_loss: 0.25092217326164246, Classifier_loss: 1.5883262157440186\n",
            "Epoch [6/10], Step [1/469], Generator_loss: 0.23724298179149628, Classifier_loss: 1.5304844379425049\n",
            "Epoch [6/10], Step [101/469], Generator_loss: 0.22024326026439667, Classifier_loss: 1.555025339126587\n",
            "Epoch [6/10], Step [201/469], Generator_loss: 0.20824575424194336, Classifier_loss: 1.6517279148101807\n",
            "Epoch [6/10], Step [301/469], Generator_loss: 0.20021796226501465, Classifier_loss: 1.5773097276687622\n",
            "Epoch [6/10], Step [401/469], Generator_loss: 0.1935100555419922, Classifier_loss: 1.554133653640747\n",
            "Epoch [7/10], Step [1/469], Generator_loss: 0.1909257024526596, Classifier_loss: 1.5644692182540894\n",
            "Epoch [7/10], Step [101/469], Generator_loss: 0.18709509074687958, Classifier_loss: 1.5623176097869873\n",
            "Epoch [7/10], Step [201/469], Generator_loss: 0.18371076881885529, Classifier_loss: 1.5575025081634521\n",
            "Epoch [7/10], Step [301/469], Generator_loss: 0.18114806711673737, Classifier_loss: 1.5972033739089966\n",
            "Epoch [7/10], Step [401/469], Generator_loss: 0.17801909148693085, Classifier_loss: 1.5904592275619507\n",
            "Epoch [8/10], Step [1/469], Generator_loss: 0.1760949343442917, Classifier_loss: 1.602091908454895\n",
            "Epoch [8/10], Step [101/469], Generator_loss: 0.1742682009935379, Classifier_loss: 1.547867774963379\n",
            "Epoch [8/10], Step [201/469], Generator_loss: 0.17217262089252472, Classifier_loss: 1.510469675064087\n",
            "Epoch [8/10], Step [301/469], Generator_loss: 0.1694076955318451, Classifier_loss: 1.5624947547912598\n",
            "Epoch [8/10], Step [401/469], Generator_loss: 0.16684281826019287, Classifier_loss: 1.5808993577957153\n",
            "Epoch [9/10], Step [1/469], Generator_loss: 0.16566576063632965, Classifier_loss: 1.5998671054840088\n",
            "Epoch [9/10], Step [101/469], Generator_loss: 0.16368810832500458, Classifier_loss: 1.6450704336166382\n",
            "Epoch [9/10], Step [201/469], Generator_loss: 0.16132228076457977, Classifier_loss: 1.6098484992980957\n",
            "Epoch [9/10], Step [301/469], Generator_loss: 0.15926754474639893, Classifier_loss: 1.605290412902832\n",
            "Epoch [9/10], Step [401/469], Generator_loss: 0.15657417476177216, Classifier_loss: 1.5603992938995361\n",
            "Epoch [10/10], Step [1/469], Generator_loss: 0.15547509491443634, Classifier_loss: 1.5513157844543457\n",
            "Epoch [10/10], Step [101/469], Generator_loss: 0.15321019291877747, Classifier_loss: 1.5703121423721313\n",
            "Epoch [10/10], Step [201/469], Generator_loss: 0.15127836167812347, Classifier_loss: 1.5706751346588135\n",
            "Epoch [10/10], Step [301/469], Generator_loss: 0.1495121270418167, Classifier_loss: 1.547392725944519\n",
            "Epoch [10/10], Step [401/469], Generator_loss: 0.14763183891773224, Classifier_loss: 1.597184658050537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uEIlGkFOxtG",
        "outputId": "0f6dda67-089f-4040-cac4-d321e4345aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "iter2 = iter(train_loader)\n",
        "x,y = next(iter2)\n",
        "generator(x.cuda())"
      ],
      "id": "2uEIlGkFOxtG",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-e857f1f6a0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '_SingleProcessDataLoaderIter' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28dlb7ciW9nP"
      },
      "source": [
        ""
      ],
      "id": "28dlb7ciW9nP",
      "execution_count": null,
      "outputs": []
    }
  ]
}