{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FGSM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uiflfa3DbKn"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np "
      ],
      "id": "1uiflfa3DbKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-wealth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0c452c-cbda-42f0-d8af-e3e7ddd02660"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "train_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=True\n",
        ")\n",
        "\n",
        "test_set = MNIST(\n",
        "    './', \n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(), \n",
        "    train=False\n",
        ")"
      ],
      "id": "behind-wealth",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-18 07:49:35--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-08-18 07:49:35--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [            <=>     ]  33.20M  6.30MB/s    in 5.5s    \n",
            "\n",
            "2021-08-18 07:49:42 (6.01 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vertical-venice"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=128, shuffle=False)"
      ],
      "id": "vertical-venice",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwUQXUuDEQ4t"
      },
      "source": [
        "# A simple convolutional classifier\n",
        "class ConvClassifier(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, input_shape=np.array([28,28])):\n",
        "    super().__init__()\n",
        "    self.input_shape = input_shape\n",
        "    self.cnn = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Linear(out_channels * np.prod(self.input_shape) // 16, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return self.linear(x)"
      ],
      "id": "OwUQXUuDEQ4t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bC-zfNNJfTJ"
      },
      "source": [
        "# HYPERPARAMETERS\n",
        "epochs = 5\n",
        "lr = 0.001\n",
        "epsilon = 0.1\n",
        "\n",
        "# Standard (non-adversarial) training loop\n",
        "def train(device, train_loader, model):\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for i, (x,y) in enumerate(train_loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      logits = model(x)\n",
        "      loss = loss_fn(logits, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i%100 == 0):\n",
        "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch+1, epochs, i+1, len(train_loader), loss.item()))\n"
      ],
      "id": "3bC-zfNNJfTJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7QGk_KjJlZf"
      },
      "source": [
        "model = ConvClassifier(1, 4).cuda()"
      ],
      "id": "I7QGk_KjJlZf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz0kOY4sJp58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178afd00-6443-478f-b5dc-779914f28161"
      },
      "source": [
        "train(device, train_loader, model) # gey ata"
      ],
      "id": "nz0kOY4sJp58",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/469], Loss: 2.479057788848877\n",
            "Epoch [1/5], Step [101/469], Loss: 0.5927906632423401\n",
            "Epoch [1/5], Step [201/469], Loss: 0.3305518925189972\n",
            "Epoch [1/5], Step [301/469], Loss: 0.25751420855522156\n",
            "Epoch [1/5], Step [401/469], Loss: 0.15906080603599548\n",
            "Epoch [2/5], Step [1/469], Loss: 0.20467111468315125\n",
            "Epoch [2/5], Step [101/469], Loss: 0.18018808960914612\n",
            "Epoch [2/5], Step [201/469], Loss: 0.160672128200531\n",
            "Epoch [2/5], Step [301/469], Loss: 0.1707994043827057\n",
            "Epoch [2/5], Step [401/469], Loss: 0.13455817103385925\n",
            "Epoch [3/5], Step [1/469], Loss: 0.07427234202623367\n",
            "Epoch [3/5], Step [101/469], Loss: 0.17444077134132385\n",
            "Epoch [3/5], Step [201/469], Loss: 0.1609479933977127\n",
            "Epoch [3/5], Step [301/469], Loss: 0.12243125587701797\n",
            "Epoch [3/5], Step [401/469], Loss: 0.0548778772354126\n",
            "Epoch [4/5], Step [1/469], Loss: 0.1775771528482437\n",
            "Epoch [4/5], Step [101/469], Loss: 0.05574285611510277\n",
            "Epoch [4/5], Step [201/469], Loss: 0.09769746661186218\n",
            "Epoch [4/5], Step [301/469], Loss: 0.07731150090694427\n",
            "Epoch [4/5], Step [401/469], Loss: 0.038225166499614716\n",
            "Epoch [5/5], Step [1/469], Loss: 0.12334277480840683\n",
            "Epoch [5/5], Step [101/469], Loss: 0.11739672720432281\n",
            "Epoch [5/5], Step [201/469], Loss: 0.05914442986249924\n",
            "Epoch [5/5], Step [301/469], Loss: 0.04440553858876228\n",
            "Epoch [5/5], Step [401/469], Loss: 0.06907432526350021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uEIlGkFOxtG"
      },
      "source": [
        ""
      ],
      "id": "2uEIlGkFOxtG",
      "execution_count": null,
      "outputs": []
    }
  ]
}