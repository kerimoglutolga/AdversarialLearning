{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerimoglutolga/AdversarialLearning/blob/master/finalreport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "U5guSL0J2JFQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "n_epochs = 5\n",
        "batch_size_train = 64\n",
        "batch_size_test = 64\n",
        "learning_rate = 0.001\n",
        "momentum = 0.5\n",
        "log_interval = 100"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hGmjHHd_2JFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "yfCnQWjN26ce"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                               transform=torchvision.transforms.Compose([\n",
        "                                   torchvision.transforms.ToTensor(),\n",
        "                                   #torchvision.transforms.Normalize(\n",
        "                                   #    (0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size_train, shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                               transform=torchvision.transforms.Compose([\n",
        "                                   torchvision.transforms.ToTensor(),\n",
        "                                   #torchvision.transforms.Normalize(\n",
        "                                    #   (0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size_test, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hX3UqV1t2JFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(1,10, kernel_size=5), nn.MaxPool2d(kernel_size=2), nn.ReLU(),\n",
        "                  nn.Conv2d(10, 10, kernel_size=5), nn.Dropout2d(),\n",
        "                  nn.MaxPool2d(kernel_size=2), ]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YsssAs1t2JFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim=160):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(input_dim, 50), nn.ReLU(), nn.Dropout(),\n",
        "                  nn.Linear(50, 10)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.net(x), dim=1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-3aXkUzQ2JFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.mlp = MLP()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x).view(x.shape[0], -1)\n",
        "        return self.mlp(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jDAa4MBM2JFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_attack(model, images, labels, eps=0.3, alpha=2/255, iters=30) :\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    ori_images = images.data\n",
        "\n",
        "    for i in range(iters) :    \n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        model.zero_grad()\n",
        "        cost = loss(outputs, labels).to(device)\n",
        "        images.retain_grad()\n",
        "        cost.backward()\n",
        "\n",
        "        adv_images = images + alpha*images.grad.sign()\n",
        "        eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
        "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
        "            \n",
        "    return images"
      ],
      "metadata": {
        "id": "M5kl5xmG4wLK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "network = Classifier().to(device)\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate);"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uiYXrAbx2JFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "u6iHsa_A2JFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(epoch, adv=False, mix_rate=0.5):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    network.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        if adv:\n",
        "          val = torch.rand(1)\n",
        "          if val < mix_rate:\n",
        "            data = pgd_attack(network, data, target)\n",
        "        optimizer.zero_grad()\n",
        "        output = network(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            train_losses.append(loss.item())\n",
        "            train_counter.append(\n",
        "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Av-coSmb2JFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def test(adv=False):\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      if adv:\n",
        "        data = pgd_attack(network, data, target)\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  if adv:\n",
        "    print('Test set: Avg. adversarial loss: {:.4f}, Adversarial Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  else: print('Test set: Avg. natural loss: {:.4f}, Natural Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z1tIMt-L2JFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306208\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.050902\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.654316\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.589659\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.402009\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.633114\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.397437\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.446245\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.386608\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.451197\n",
            "Test set: Avg. natural loss: 0.0026, Natural Accuracy: 9475/10000 (95%)\n",
            "Test set: Avg. adversarial loss: 0.1118, Adversarial Accuracy: 41/10000 (0%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.373952\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.351291\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.260698\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.281024\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.268859\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.394074\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.633293\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.267088\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.344228\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.272926\n",
            "Test set: Avg. natural loss: 0.0018, Natural Accuracy: 9601/10000 (96%)\n",
            "Test set: Avg. adversarial loss: 0.1304, Adversarial Accuracy: 52/10000 (1%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.242357\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.282595\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.278883\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.336691\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.414422\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.253113\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.320649\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.264458\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.046604\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.275087\n",
            "Test set: Avg. natural loss: 0.0015, Natural Accuracy: 9661/10000 (97%)\n",
            "Test set: Avg. adversarial loss: 0.1421, Adversarial Accuracy: 68/10000 (1%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.381756\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.455164\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.331362\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.218709\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.356242\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.186470\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.400191\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.299283\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.264874\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.269880\n",
            "Test set: Avg. natural loss: 0.0013, Natural Accuracy: 9701/10000 (97%)\n",
            "Test set: Avg. adversarial loss: 0.1567, Adversarial Accuracy: 38/10000 (0%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.229842\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.164872\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.157633\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.193868\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.244692\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.100661\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.161370\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.140891\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.198436\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.390701\n",
            "Test set: Avg. natural loss: 0.0012, Natural Accuracy: 9730/10000 (97%)\n",
            "Test set: Avg. adversarial loss: 0.1740, Adversarial Accuracy: 24/10000 (0%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Regular training\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "    test(adv=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nTp2NIRv2JFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b76128a-0e93-4a77-b38f-cc4ba4130241"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial training\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch, adv=True, mix_rate=1)\n",
        "    test()\n",
        "    test(adv=True)"
      ],
      "metadata": {
        "id": "aJ3cEHdwIWvy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "4cfa9f4a-f05d-4afb-f7e6-66a9a1cfa85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 9.029798\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.722981\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.956147\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.524281\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.227952\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.343105\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.304679\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.513231\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.343359\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-081ec64ab5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmix_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-6c8aaad1280b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, adv, mix_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmix_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-7a56b7e24972>\u001b[0m in \u001b[0;36mpgd_attack\u001b[0;34m(model, images, labels, eps, alpha, iters)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(network, \"85-69.pth\")"
      ],
      "metadata": {
        "id": "vF8gORH5P9az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = torch.load(\"85-69.pth\")"
      ],
      "metadata": {
        "id": "WAd9OdYFRMli"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "labels = []\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "network.eval()\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data = pgd_attack(network, data, target)\n",
        "    optimizer.zero_grad()\n",
        "    with torch.no_grad():\n",
        "      output = np.reshape(network.encoder(data).cpu().detach().numpy(), (64, -1))\n",
        "      target = target.cpu().detach().numpy()\n",
        "      output_list = np.split(output, 64)\n",
        "      target_list = np.split(target, 64)\n",
        "      features.extend(output_list)\n",
        "      labels.extend(target_list)"
      ],
      "metadata": {
        "id": "uMkv2I8LCUEu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "features = np.squeeze(features, 1)\n",
        "labels = np.squeeze(labels, 1)"
      ],
      "metadata": {
        "id": "NWw0dWCetzf_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "01Qnqvgi1oSS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = SVR(kernel=\"linear\")\n",
        "selector = RFE(estimator, n_features_to_select=40, step=1)\n",
        "selector = selector.fit(features, labels)"
      ],
      "metadata": {
        "id": "5AXsgA88Q-rr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "36i_tE47w3vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = selector.get_support()\n",
        "np.save(\"indices\")"
      ],
      "metadata": {
        "id": "hQG4Zgz0kxm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "a606b224-2450-4134-d032-7d18b23d0cff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c9e81e44a99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"indices.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = np.load(\"features.npy\")"
      ],
      "metadata": {
        "id": "mEuekLFogPi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP train\n",
        "new_model = MLP(30).cuda()\n",
        "def post_train(epoch, adv=False, mix_rate=0.5):\n",
        "    optimizer = torch.optim.Adam(new_model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    network.eval()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = np.reshape(network.encoder(data).cpu().detach().numpy(), (64, -1))\n",
        "        output = output[:, selected_features == 1]\n",
        "        output = torch.from_numpy(output).float().cuda()\n",
        "        if adv:\n",
        "          val = torch.rand(1)\n",
        "          if val < mix_rate:\n",
        "            data = pgd_attack(new_model, output, target)\n",
        "        output = new_model(output)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            train_losses.append(loss.item())\n",
        "            train_counter.append(\n",
        "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ],
      "metadata": {
        "id": "0nehrMqXRkre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_test(model,adv=False):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      if adv:\n",
        "        data = pgd_attack(network, data, target)\n",
        "        output = np.reshape(network.encoder(data).cpu().detach().numpy(), (64, -1))\n",
        "        output = output[:, selected_features == 1]\n",
        "        output = torch.from_numpy(output).float().cuda()\n",
        "        output = new_model(output)\n",
        "      test_loss += F.nll_loss(output, target).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  if adv:\n",
        "    print('Test set: Avg. adversarial loss: {:.4f}, Adversarial Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  else: print('Test set: Avg. natural loss: {:.4f}, Natural Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "ROVn7RjUWjyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    post_train(epoch)\n",
        "    post_test(new_model)\n",
        "    post_test(new_model, adv=True)"
      ],
      "metadata": {
        "id": "zR-NRNBvVC2S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "2db50c80-bc74-47db-fc59-ed52b3a2109d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-67cbdaa47157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpost_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpost_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpost_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-82230dc2407e>\u001b[0m in \u001b[0;36mpost_train\u001b[0;34m(epoch, adv, mix_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 160 but corresponding boolean dimension is 80"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    post_train(epoch, adv=True, mix_rate=1)\n",
        "    post_test(new_model)\n",
        "    post_test(new_model, adv=True)"
      ],
      "metadata": {
        "id": "VEjJNGyhX4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JCdFkBjmwTb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "finalreport.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}